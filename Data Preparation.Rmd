---
title: "Data Preparation"
author: "DARS"
date: "`r Sys.Date()`"
output: 
  github_document:
    toc: TRUE
editor_options: 
  chunk_output_type: console
---

TODO:

* when student takes a course multiple times:
    * keep lowest grade
    * keep highest grade 
    * or keep both (much more complex)

```{r setup, include = FALSE}
knitr::opts_chunk$set(cache.path = "Cache/Data Preparation/")

library(tidyverse)
library(tidytext)
library(gsheet) # import spreadsheets from google drive
library(tm)
library(hunspell) # Stemmer
```

# Import Data
The datasets we use are saved as spreadsheet on our google drive *DARS* (with exeption of grade data saved as csv files on the computer for privacy reasons). We use the function `gsheet2tbl` to import them to `R Studio` as tibbles. We use the tibble data format (an evolution of the data frame format) because this is the format of reference of the `tidyverse` on whose tools our analysis is heavily based.

## List of AoD's and Assessments
First, we import the spreadsheet with information pertraining the Aims of the Degree (AoD) and Assessments from the drive and save it under `lists_brut`. ` lists_brut` contains 4 columns, under which we find the `19` types of assessment, the `18` aims of the degree (AoD) of the degree, and  two columns containing binary vectors indicating which assessment types and AoD  we will consider when ploting the data[^1].
Then we create a list with this same columns, but instead of having binary vectors for the plots, we keep vectors of only the names of relevant assessments and AoDs for the plots (`Assessment_plot`adnd `AoD_plot` respectively). We also any imported emtpy cells.
```{r list_AoD_assessment}
list_AoD_assessment <- gsheet2tbl('https://docs.google.com/spreadsheets/d/1soRA1u5zf9oLNirGmZ9yZ7m2ccPa3XFemnxkj5AVRXo/edit#gid=1239912347') %>%
  
  map(na.omit)

# selection of most important types of assessment an AoD to keep plots clear
list_AoD_assessment$`Assessment for Plot` <- list_AoD_assessment$Assessment[list_AoD_assessment$`Assessment for Plot` == 1] %>% print
list_AoD_assessment$`Aim for Plot`        <- list_AoD_assessment$Aim       [list_AoD_assessment$`Aim for Plot`        == 1] %>% print
```

## Course Data
We import three spreadsheets from the drive and transform them into the so-called *tidy format*. The tibble `d_course` contains information at the course-level such as in which cluster and concentration(s) they belong, and in which period(s) they are offered. The tibble `d_assessment` indicates which type(s) of assessment each course contains with one row per course-assessment; and the tibble `d_ILO` indicates which AoD(s) the intended learning objectives (ILOs) of the courses cover with one row per course-ILO-AoD.

```{r d_course}
d_course <- gsheet2tbl('https://docs.google.com/spreadsheets/d/1soRA1u5zf9oLNirGmZ9yZ7m2ccPa3XFemnxkj5AVRXo/edit#gid=1655700848') %>% print
```

```{r d_assessment}
d_assessment <- gsheet2tbl('https://docs.google.com/spreadsheets/d/1soRA1u5zf9oLNirGmZ9yZ7m2ccPa3XFemnxkj5AVRXo/edit#gid=1102665750') %>%
  
  mutate_if(is.numeric, as.logical) %>%
  
  # Transform data into tidy format to facilitate manipulation
  gather(
    key   = Assessment, 
    value = assessment_covered,
    Paper : Participation
    ) %>%
  
  filter(assessment_covered) %>%
  
  select(- c(assessment_covered, `Comment on Assessment`)) %>%
  
  print
```

```{r d_ILO}
d_ILO <- gsheet2tbl('https://docs.google.com/spreadsheets/d/1soRA1u5zf9oLNirGmZ9yZ7m2ccPa3XFemnxkj5AVRXo/edit#gid=1896457050')
```

```{r d_AoD_from_ILO}
d_AoD_from_ILO <- d_ILO %>%
  
  rename(ILO = Objectives) %>%
  
  mutate_if(is.numeric, as.logical) %>%
  
  # Transform data into tidy format to facilitate manipulation
  gather(
    key   = AoD, 
    value = AoD_covered,
    `Matrix Complete` : `Intercultural Skills`
    ) %>%
  
  filter(AoD_covered) %>%
  
  select(- c(AoD_covered, Comments, Comments_for_Jeroen)) %>%
  
  print
```

## Textual Data
In order to conduct a preliminary topic modeling of course content, we first analyze their description in the course catalogues. The corpus `corpus_catalogues` contains the pdfs of the `5` most recent course catalogues.

```{r read_in_pdfs}
# helper function
read_in_pdfs <- function(file){
  
  Corpus(
    x             = DirSource(file),
    readerControl = list(reader = readPDF(control = list(text = "-layout")))
    ) %>%
    
    # turn corpus into a list to facilitate manipulation
    as.list %>%
    
    unname
  
}
```

```{r catalogues, cache = TRUE}
d_text <- list()

d_text$catalogues <- "./Input/Catalogues" %>%
  read_in_pdfs %>%
  map(function(x) x$content)
```

To expand our topic modeling of course content, we analyse the material in the course manuals. The `corpus_manuals` contains the pdfs of the course manuals for the year 2017-2018 (most recently, available).

```{r extract_code}
# helper functions
extract_code <- function(string) string %>% str_sub(start = 1, end = 7)
```

```{r manuals, cache = TRUE}
d_text$manuals <- "./Input/Manuals 2017-18" %>%
  
  read_in_pdfs %>%
  
  # turn list into a tibble to facilitate manipulation
  tibble(manuals = .) %>%
  
  transmute(
    `Course ID` = manuals %>% map(function(x) x$meta$id) %>% map_chr(extract_code),
    year        = "2017-2018",
    text        = manuals %>% map(content) %>% map_chr(str_c, collapse = " ")
    ) %>%
  
  print

rm(read_in_pdfs)
```

## Student Data
The tibble `d_transcript` contains the transcript information of students as was provided. It has 40 columns, and rows correspond to a type of grade (e.g. final grade, attendance) per student per course per time they took it.

```{r read_csv_own_parsing}
# set up
col_parsing <- cols(
  `Student Number`                      = "c",
  `Program (Abbreviation)`              = "c",
  `Appraisal Status`                    = "c",
  `Module Booking Reason (Description)` = "c",
  `Object name`                         = "c",
  `Start date`                          = "c",
  `End Date`                            = "c"
  )

# helper function
read_csv_own_parsing <- function(file) file %>% read_csv(col_types = col_parsing)
```

```{r d_transcript, cache = TRUE}
d_transcript <- paste0("Input/Raw Grades/grades", 1:2, ".csv") %>%
  map(read_csv_own_parsing) %>%
  bind_rows

rm(col_parsing, read_csv_own_parsing)
```

# Variable Engineering
## Course Data
The analysis performed on the course data is aimed at discoving what the contribution of each course is towards the fullfilment of the AoDs, and comparing different types of curricula, or programs, based on this infromation. 

### AoD
In this analysis, we conside that a course can cover an AoD in two ways: a course covers an AoD if one of its ILOs covers it, or if one of its assessments cover it. For instance, if one of ILO of a course states that the students will learn to analyze empirical data in the context of academic research, then the course in question covers the AoD `Research Skills`; and if one of the assessment is a group presentation, then the course also covers the AoD `Collaborative Skills` and `Communication Skills`.

#### AoD from ILOs
(For this section we use: `d_ILO`-indicates which AoD(s) the intended learning objectives (ILOs) of the courses cover with one row per course-ILO-AoD)

In order to determine which AoD each course covers with its ILOs, we first eliminate the AoD that are not covered by the ILOs, and then we keep only one instance of each combination of course and AoD in case a course had several ILOs covering the same AoD.
```{r d_AoD_ILO}
d_AoD_from_ILO
```

#### AoD from Assessment
(For this section we use: `d_assessment`-indicates which type(s) of assessment each course contains with one row per course-assessment)

In order to determine which AoD each course covers with its assessments, we need to create a binary matrix which indicates which AoD(s) each assessment type covers. We have created such matrix on our google drive and we save it in the following piece of code as `map_assessment_AoD`. `map_assessment_AoD` indicates that, for instance, the assessment type `Essay` covers the AoD `Critical Thinking Skills`, `Communication Skills` and `Writing Skill`. Thus, the first step is to import this matrix:

```{r map_assessment_AoD}
map_assessment_AoD <- gsheet2tbl('https://docs.google.com/spreadsheets/d/1soRA1u5zf9oLNirGmZ9yZ7m2ccPa3XFemnxkj5AVRXo/edit#gid=719531216') %>%
  
  mutate_if(is.numeric, as.logical) %>%
  
  # Transform data into tidy format to facilitate manipulation
  gather(
    key   = AoD, 
    value = AoD_covered,
    `Matrix Complete` : `Intercultural Skills`
    ) %>%
  
  filter(AoD_covered) %>%
  
  select(- AoD_covered) %>%
  
  arrange(Assessment) %>%
  
  print
```

Now that we have the matrix `map_assessment_AoD`, we want to find out which AoDs are covered by a course through its assessments. To do this we create an empty tibble `d_AoD_assessment` to store which assessment is covered by each course, and which AoD said assessment covers.Then, we fill in the information with a loop.
In the loop, we first extract a row of `d_assessment` and save it as `observation`. Then, we determine the corresponding assessment which we save as `assessment`. Then, we use the matrix `map_assessment_AoD` to determine which AoD `assessment` covers and use `cbind` and `rbind` to add the information to the tibble `d_AoD_assessment`.
```{r d_AoD_assessment}
d_AoD_from_assessment <- d_assessment %>%
  
  left_join(map_assessment_AoD, by = "Assessment") %>%
  
  print

rm(map_assessment_AoD)
```

#### Combining AoD from ILOs and from assessments
Finally, we can use a `rbind` to combine the two tibbles `d_AoD_ILO` and `d_AoD_assessment`. We also use `distinct` in case a course covers an AoD with both its ILOS and its assessments.
```{r rbind d_AoD_ILO and d_AoD_assessment}
d_AoD <- rbind(
  d_AoD_from_ILO        %>% select(`Course ID`, AoD),
  d_AoD_from_assessment %>% select(`Course ID`, AoD)
  ) %>%
  
  distinct %>%
  
  arrange(`Course ID`) %>%
  
  print

rm(d_AoD_from_assessment, d_AoD_from_ILO)
```

### Courses
(In this section we use: `d_course`- contains information at the course-level such as in which cluster and concentration(s) they belong, and in which period(s) they are offered.)

Now that we have a clear overview of the distribution of AoDs (`d_AoD`) and assessments (`d_assessment`) among the courses, let us add variables to the tibble `d_course` that contain the information at the course level. For this we create the following three tibbles:
1) `d_ILO_detail` contains two columns indicating the code of the course and the number of ILOs it contains.
2) `d_assessment_detail` contains three columns indicating the code of the course, the number of assessments it covers and a list of the assessments it covers. 
3) `d_AoD_detail` contains three columns indicating the code of the course, the number of AoD it covers and a list of the AoD it covers. 
Then we use a `full_join` to add these variables to the tibble `d_course`.
```{r d_course detail}
# helper function
count_and_paste <- function(df, var, colnam1, colnam2){
  
  df %>%
    
    group_by(`Course ID`) %>%
    
    summarize(
      !!ensym(colnam1) := n_distinct(!!enquo(var)),
      !!ensym(colnam2) := str_c(!!enquo(var), collapse = ", ")
      )
  
}

# helper function
join_by_course_ID <- function(df1, df2) left_join(df1, df2, by = "Course ID")
```

```{r join d_course_detail}
d_course <- d_course %>%
  
  join_by_course_ID( d_AoD %>% count_and_paste(AoD, n_AoD, `AoD Covered`) %>% print) %>%
  
  join_by_course_ID( d_assessment %>% count_and_paste(Assessment, n_assessment, `Assessments Covered`) ) %>%
  
  join_by_course_ID( d_ILO %>% count_and_paste(Objectives, n_ILO, `ILO Covered`        ) ) %>%
  
  select(
    `Course ID`, `Course Title`, Cluster,
    n_ILO,
    n_assessment, `Assessments Covered`,
    n_AoD, `AoD Covered`,
    everything()
    ) %>%
  
  print

rm(count_and_paste, join_by_course_ID)
```

The undegraduate research courses (*UGR-*) are only present at the `3000` level (advanced level). Yet, these course are also offered at the `2000` level (intermediate level). We use an `rbind` to duplicate the rows of the course `UGR3000` and mutate their `Code` to `UGR2000`.
```{r create UGR2000}
UGR_2000 <- d_course %>%
  
  filter( `Course ID` %in% c("UGR3001", "UGR3002", "UGR3003", "UGR3005")) %>%
  
  mutate(
    `Course ID` = case_when(
      `Course ID` == "UGR3001" ~ "UGR2001",
      `Course ID` == "UGR3002" ~ "UGR2002",
      `Course ID` == "UGR3003" ~ "UGR2003",
      `Course ID` == "UGR3005" ~ "UGR2005"
      )
    ) %>%
  
  print

d_course <- d_course %>% rbind(UGR_2000)

# print UGR course
print(d_course %>% filter(str_detect(`Course ID`, "UGR") ) )

rm(UGR_2000)
```

Finally, we add a series of informative variable at the course level.
```{r d_course additional info}
d_course <- d_course %>%
  
  separate(
    col     = `Course ID`,
    into    = c("Letters", "Number"),
    sep     = 3,
    remove  = FALSE,
    convert = TRUE
    ) %>%
  
  mutate(
    Level   = case_when(
      between(Number, 1000, 1999) ~ "Introductory",
      between(Number, 2000, 2999) ~ "Intermediate",
      between(Number, 3000, 3999) ~ "Advanced"    )
    ) %>%
  
  select(`Course ID`, Letters, Number, Level, everything()
    ) %>%
  
  print
```


## Textual Data
### Extracting Overviews
In order to conduct a topic analysis of course content, we extract the *overview* and *description* of each course from the course catalogues, as well as the  *full text*  from the Course Manuals.

(For this section we use:`corpus_catalogues` contains the pdfs of the `5` most recent course catalogues.)

We start by extracting the overviews which are 1 or 2 page long and contain important information of a course. To accomplish this, for each catalogue (loop), we first use `grep` to determine which pages should be excluded from the analysis (`pages_to_exclude`). These pages are typically headers. Excluding them before the analysis allows use to keep the code relatively simple. We also make use the fact that the overviews always start with the code of the course, i.e. it starts with one of the elements of `course_code`; and we use `grep` to identify the first page of each overview. We use grep a 3rd time to identify the page containing the header *Core Coureses (COR)* and which marks the beginning of the overviews in the catalogue, and we loop from this page to the last page of the catalogue.

In the loop, we first determine the content of the current and following page. If the current page is the first page of an overview, then we identify the overview (one or two pages) and save it to the tibble `d_description`. To identify the overview of a course, we check if the following page is either the first page of an overview or a page to exclude. If it is either of these, then the overview correspond to the content of the current page; but if the following page is neiter of these, then the overview correspond to the content of the current page and that of the following page.

```{r overview set up}
# Set up
collapse_or <- function(string) string %>% str_c(collapse = "|")

headers <- c(
  "^Core Courses \\(COR\\)",
  "^Humanities \\(HUM\\)",
  "^Sciences \\(SCI\\)",
  "^Social Sciences \\(SSC\\)",
  "^Skills Trainings? \\(SKI\\)",
  "^Projects? \\(PRO\\)",
  "^Undergraduate Research", "UCM Undergraduate\r\n ? ?Research",
  "Appendix"
  ) %>%
  collapse_or

overview_start <- c(
  "COR",
  "HUM", "SCI", "SSC", 
  "SKI", "PRO",
  "UGR", "CAP"
  ) %>% 
  collapse_or

years <- paste0(2014:2018, "-", 2015:2019)
```

```{r overview helper functions}
# helper functions in order of use
is_start_overview_section  <- function(string) string %>% str_detect(pattern = "^Core Courses \\(COR\\)")
is_end_overview_section    <- function(string) string %>% str_detect(pattern = "Appendix")
is_header                  <- function(string) string %>% str_detect(pattern = headers)

is_overview_start          <- function(string) string %>% extract_code %>% str_detect(pattern = overview_start)
paste_if_two_page_overview <- function(page, page_following){
  
  if(page %>% is_overview_start){
    
    if(page_following %>% is_overview_start | is.na(page_following))  page # include possibility of `is.na(page_following)` for last page of overview section
    else                                                              paste(page, page_following)
  
  }else                                                               NA_character_   # if the page is not the start of an overview, return an NA
  
}

add_year <- function(x, yr) x %>% mutate(year = yr)
```

```{r extract_overview}
extract_overview <- function(catalogue){
  
  # create tibble to facilitate manipulation
  catalogue %>% 
    tibble(page = .) %>%
    
  # identify start and end of overview section of catalogue
    mutate(
      is_start_overview_section = page %>% is_start_overview_section,
      is_end_overview_section   = page %>% is_end_overview_section
      ) %>%
    
    # I have checked that there is one and only one is_start_overview_section and no more than 1 is_end_overview_section
      # if(sum(catalogue_all$is_start_overview_section) == 0) print("error: no overview_section_start"      )
      # if(sum(catalogue_all$is_start_overview_section) >  1) print("error: multiple overview_section_start")
      # if(sum(catalogue_all$is_end_overview_section  ) >  1) print("error: multiple overview_section_end"  )
    
    # filter the overview section
    mutate(
      is_after_start_overview_section = cumany( is_start_overview_section),
      is_before_end_overview_section  = cumall(!is_end_overview_section  ),
      is_overview_section             = is_after_start_overview_section & is_before_end_overview_section
      ) %>%
    filter(is_overview_section) %>%
    
    # exclude headers to only keep the overviews themselves
    filter(! page %>% is_header) %>%
    
    # paste current page and following page (`lead(page)`) if overview is two page long
    transmute(
      text        = list(page, lead(page)) %>% pmap_chr(paste_if_two_page_overview),
      `Course ID` = text %>% extract_code
      ) %>%
    filter(!is.na(text))
    
}
```

```{r overview, cache = TRUE}
d_text$overview <- d_text$catalogues %>%
  
  map(extract_overview) %>%
  
  # add the year to each observation to keep track of the evolution of the catalogue over time
  map2(years, add_year) %>%
  
  # turn list into a tibble to facilitate manipulation
  bind_rows(d_text$overview) %>%
  print

# only keep the overviews and manuals for clarity
d_text <- d_text[c("overview", "manuals")]

rm(
  headers, overview_start,
  is_start_overview_section, is_end_overview_section, is_header, is_overview_start,
  paste_if_two_page_overview, extract_overview,
  years
  )
```

### Extracting Descriptions
Since the overviews contain a lot of information that does not interest us, we extract the description section from the overviews. The description section contains a brief description (200-500 words) of the content of the course. To accomplish this, for each overview, we need to identify the line where the description starts and the line where it ends. The description section is always preceeded by a header saying *Description* or *Course Description* (`start_descrip`), making it relatively easy to find the starting line of the decription section with `grep`. The description section is usually followed by the literature section which starts with header saying *Literature*, *Recommended Literature* or similar (see `end_descrip`). Using `grep` together with `end_descrip`, we can again identify the ending line of the description section of almost all overviews. A handful overviews do not contain a *Literature* section. For these, the section *Instructional Format* marks the end of the description section.

```{r description set up}
# Setup
symbol_to_line <- c("\r\n", "\n") %>% collapse_or
start_descrip  <- c("^Description", "^Course Description") %>% collapse_or
end_descrip    <- c(
  "^Recommended Literature", "^ ?Required Litera", "^ ?Literature$", "Literature \\(all",
  "^Instructional format$"
  ) %>% collapse_or
```

```{r description helper function}
# helper functions
split              <- function(string) string %>% str_split (pattern = symbol_to_line) %>% .[[1]]

is_start_descrip   <- function(string) string %>% str_detect(pattern = start_descrip )
is_end_descrip     <- function(string) string %>% str_detect(pattern = end_descrip   )
```

```{r extract_description}
extract_description <- function(overview){
  
  overview %>%
    split %>%
    tibble(line = .) %>%
    
    mutate(
      is_start_descrip = line %>% is_start_descrip,
      is_end_descrip   = line %>% is_end_descrip # Having multiple ends (e.g. "literature" and "instructional format") is ok because we only use the first (cumany)
      ) %>%
  
    # filter the description section
    mutate(
      is_after_start_descrip = cumany( is_start_descrip),
      is_before_end_descrip  = cumall(!is_end_descrip  ),
      is_descrip             = is_after_start_descrip & is_before_end_descrip
      ) %>%
    
    filter(is_descrip, !is_start_descrip, !is_end_descrip) %>%
    
    summarise(description = str_c(line, collapse = " ")) %>%
    
    pull
  
}
```

```{r description}
d_text$description <- d_text$overview %>%
  mutate(text = text %>% map_chr(extract_description))
```

### Tidy Text Format
To put everything into tidy text format, we first create three tibbles `d_overview_tidy`, `d_description_tidy`, `d_manual` that respectively store the overviews, descriptions and text from manuals in the tidy text format, with one row per course-year-word (and course-word for `d_manual`).
```{r tidy_text}
# helper function
tidy_text <- function(df){
  
  df %>%
    unnest_tokens(
      output = word,
      input  = text
      )
  
}
```

```{r tidy d_text}
d_text <- d_text %>% map(tidy_text) %>% print

rm(tidy_text)
```

### Stemming
We then use the function `hunspell_stem`, which returns valid stems for a given word, to stem the words in the tibbles `d_overview_tidy` and `d_description_tidy`. 

We first create a function `stem_hunspell` which, given a term, returns its most basic stem (the last one from the list of stem returned by `hunspell_stem`). We would like to apply `stem_hunspell` on the words of `d_overview_tidy` and `d_manual`, since they have similar structures, we row bind them into `dictionary` to ease the application of `stem_hunspell`. However, since, `stem_hunspell` is not a vectorized function and the number of words in `dictionary` is large, we first use distinct on the `word` variable to find a list containing *once* each term present in the course overviews and manuals. Then, we use `mutate` to apply the function `stem_hunspell` on each word from our dictionary and save its results as a new column `word_stem`.

```{r stem}
# helper function
stem <- function(term) {
  
  stems   <- hunspell_stem(term)[[1]] # look up the term in the dictionary
  
  n_stems <- length(stems)            # number of stems
  
  if (n_stems == 0) term              # if no stems, return original term
  else              stems[[n_stems]]  # if multiple stems, return last (most basic) stem
  
}
```

```{r dictionary, cache = TRUE}
dictionary <- union(d_text$overview$word, d_text$manuals$word) %>%
  
  tibble(word = .) %>%
  
  mutate(word_stem = word %>% map_chr(stem))

# terms for which the stem differs from the original word
filter(dictionary, word != word_stem)
```

```{r destem}
# TODO: "destem" terms by hand: cuss => discuss
filter(dictionary, word_stem == "cuss")
```

Finally, we create a function `stem_with_dictionary` that performs a left join on the dataframe it takes as input with `dictionary`, thus adding the word stems to the original dataframe.

Then, we use `stem_with_dictionary` to include the stems of all words in `d_description`, `d_overview`, and `d_manual`.
```{r stem_with_dictionary}
# helper function
stem_with_dictionary <- function(data){
  
  data %>%
    
    left_join(dictionary, by = "word") %>%
    
    rename(
      word_original = word,
      word          = word_stem
      )
  
}
```

```{r stem d_text}
d_text <- d_text %>% map(stem_with_dictionary)

rm(stem_hunspell, stem_with_dictionary)
```

### Removing Stopwords
Finally, we want to filter out some uninformative words from our textual data. For this, we first store all the unwanted words in a vector `sw_owm`. We also create function `remove_sw` which receives a dataframe as input and filters out all words in `sw_own`. Then we apply this function to `d_description`, `d_overview`, and `d_manual`.
```{r sw_own}
# Own stop words
sw_own <- 1 : 1e3 %>% as.character %>% tibble( word = .)
```

```{r remove_sw}
# helper function
remove_sw <- function(data){
  
  data %>%
    
    anti_join(stop_words, by = "word") %>%
    
    anti_join(sw_own, by = "word") %>%
    
    # remove words of 1 or 2 letters
    filter(nchar(word) > 2) %>%
    
    # Remove words occuring once or twice in corpus (usually names, website links or typos)
    add_count(word) %>%
    filter(n > 2) %>%
    select(-n) %>%
    
    # remove NA
    filter(!is.na(word))
  
}
```

```{r sw d_text}
d_text <- d_text %>% map(remove_sw) %>% print

rm(sw_own, remove_sw)
```


## Student Data

* Is `Academic Work ID` a unique ID number?

* questions...

(In this section we use: `d_transcript`- contains the transcript information of students as was provided. It has 40 columns, and rows correspond roughly to a type of grade (e.g. final grade, attendance) per student per course per time they took it).

Our dataframe contains many variables and rows that are either empty or meaningless for our analysis. First, we filter, the final grades of studets to keep only relevant rows (Final Confirmed Grades are those with `Appraisal (Description)` as "Grade supervisor"). Then we select ony the 10 variables that we will use for the anlysis, and give them more comprehensible names.

```{r d_transcript set up}
# Set up
UCM_course <- d_text$overview$`Course ID` %>%
  unique %>% 
  paste(collapse = "|")
```

```{r d_transcript helper function}
# helper function
is_offered_at_UCM <- function(x) x %>% str_detect(UCM_course)
```

```{r d_transcript row selection}
d_transcript <- d_transcript %>%
  
  # for simplicity, we only keep 
  # *UCM courses*  (courses present in the UCM catalogue)
  # taken in the framework of the *BA Liberal Arts and Sciences (UCM)* (Program (Abbreviation) = 7501)
  
  filter(
    `Module (Abbrev.)` %>% is_offered_at_UCM,
    `Program (Abbreviation)` == "7501"
    ) %>%
  
  # The dataset has multiple rows for each student - course.
  # Following guidelines of Richard Vos, we only consider: 
  # `Appraisal (Description)` == "Grade supervisor"
  # and `Appraisal Type` == "7055"
  
  filter(
    `Appraisal (Description)` == "Grade supervisor",
    `Appraisal Type`          == "7055" # removes ~ 15 observations
    )
```

```{r d_transcript column selection}
d_transcript <- d_transcript %>%
  
  # Remove variables with only one value (~10)
  discard(function(x) n_distinct(x) == 1) %>%
  
  # Select: Student ID, course ID, when a course is taken and the grade 
  select(
    `Student ID`   = `Student Number`,
    `Course ID`    = `Module (Abbrev.)`,
    Year_numerical = `Academic Year`,
    Period         = `Academic Session`,
    Grade          = `Grade symbol`
    )
```

```{r clean_grade}
clean_grade <- function(grade){
  
  if(is.na(grade) | grade == "NG") grade <- "0"
  
  grade %>% str_replace(",", ".") %>% as.numeric
  
}
```

```{r clean_period}
clean_period <- function(period){
  
  # Course spanning over multiple period are recorder with a 1, 2 or 3
  if(period == 1) return("1 to 6")
  if(period == 2) return("1 to 3")
  if(period == 3) return("4 to 6")
  
  # Course spanning over a single period are recorded in the 100's, 200's, etc.
  # The digit of the hundred indicates the period.
  period %/% 100 %>% as.character
  
}
```

```{r clean_year}
clean_year <- function(year) str_c(year, year + 1, sep = "-")
```

```{r clean d_transcript}
d_transcript <- d_transcript %>%
  
  mutate(
    
    # Clean grade, period and year
    Grade          = Grade  %>% map_dbl(clean_grade ),
    Period         = Period %>% map_chr(clean_period),
    `Academic Year`= Year_numerical %>% map_chr(clean_year),
    
    # extract first period in which course spanning over mutliple periods is given
    period_numerical = substr(Period, 1, 1),
    
    # Combine year and period to have be able to order the course in time using a single variable
    time = str_c(Year_numerical, period_numerical) %>% as.numeric,
    
    grade_ceil = ceiling(Grade)
    
    )
```

```{r issue d_transcript}
d_transcript %>%
  
  # multiple rows with unique student ID - course ID - time combination.
  add_count(
    `Student ID`, `Course ID`, time,
    sort = TRUE
    ) %>%
  print

d_transcript %>%
  
  # multiple rows with unique student ID - course ID - time combination - grade.
  add_count(
    `Student ID`, `Course ID`, time, Grade,
    sort = TRUE
    ) %>%
  print

d_transcript %>%
  
  # SSC2046, a course I took, but excluded from my transcript is absent from the data set
  filter(`Student ID` == "6087587") %>%
  arrange(`Course ID`) %>%
  pull(`Course ID`)

#TODO: list issues here
```

## df tailored to pillar 1
```{r}
d_transcript_augmented <- d_transcript %>% left_join(select(d_course, - Period), by = c("Course ID"))

d_transcript_informative <- d_transcript_augmented %>%
  
  # Exclude courses taken by majority of students (uninformative)
  filter(
    Type != "Mandatory",
    ! Letters %in% c("SKI", "PRO", "SAS", "SAH", "SAC")
    ) %>%
  
  select(`Student ID`, `Course ID`, time, grade_ceil)
```

# Save Data
```{r}
save(d_course, list_AoD_assessment, d_AoD, d_assessment, d_ILO, file = "Output/data_general.RDATA")

save(d_transcript_augmented, d_transcript_informative, file = "Output/data_pillar_1.RDATA")

save(d_text, d_transcript, file = "Output/data_pillar_2.RDATA")
```

```{r}
save(d_course, d_text, d_transcript, file = "Output/data_pillar_2.RDATA")
```