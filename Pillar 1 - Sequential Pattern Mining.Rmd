---
title: "Pillar 1 - Sequential Pattern Mining"
author: "DARS"
date: "`r Sys.Date()`"
output: 
  github_document:
    toc: TRUE
---

```{r library, message = F}
library(tidyverse)

library(arules)
library(arulesSequences)
library(rlang)
```

# Setup
load previous data and create function to find courses
```{r loading data}
load("data_pillar_1.RDATA")
```

Function that returns title of a course given its code.
```{r}
find_course <- function(code){ 
  
  dataset <- d_transcript %>%
    filter(`Course ID`== code)
  
  title <- dataset$`Course Title`[1]
  
  return(title)
  
}
```


#Simple Rule Mining
##Data Exploration of Transcripts
```{r}
exploration <- d_transcript %>%
  mutate(Grade = case_when(Grade == "NG"~ "-1", #"0,0", #maybe we could just remove these from the analysis and treat them separately?
                           T~Grade),
         Grade = str_replace(string = Grade, pattern = ",",replace = "."),
         Grade = as.numeric(Grade))%>%
  filter(!is.na(Grade)) %>%
  filter(Grade != -1) #remove NG

summary(exploration)

student_statistics <- exploration %>%
  group_by(`Student ID`) %>%
  summarise(n = n(),
            Min = min(Grade), 
            Max = max(Grade), 
            Mean = mean(Grade), 
            Median = median(Grade), 
            SD = sd(Grade), 
            `Proportion Failed` = mean(Grade < 5.5))

course_statistics <- exploration %>%
  inner_join(d_course, by = "Course ID") %>%
  filter(between(Year_numerical, 2015,2016)) %>% #filter year
  group_by(`Course ID`) %>%
  summarise(n = n(),
            Min = min(Grade), 
            Max = max(Grade), 
            Mean = round(mean(Grade), 2), 
            Median = median(Grade), 
            SD = sd(Grade), 
            `Proportion Failed` = mean(Grade < 5.5)) %>%
  inner_join(select(d_course,`Course ID`, `Course Title`), by = "Course ID")


concentration_statistics <- exploration %>%
  inner_join(select(d_course,-Period, -`Period (additional)`,-`Period (additional bis)`,-`Course Title`), by = "Course ID") %>%
  #left_join(select(d_course, `Course ID`, Concentration, `Concentration (additional)`), by = "Course ID") %>%
  gather(X, Concentration, Concentration, `Concentration (additional)`, na.rm = TRUE) %>%
  group_by(Concentration) %>%
  summarise(n = n(),
            Min = min(Grade), 
            Max = max(Grade), 
            Mean = round(mean(Grade), 2), 
            Median = median(Grade), 
            SD = sd(Grade), 
            `Proportion Failed` = mean(Grade < 5.5))
  
cluster_statistics <- exploration %>%
  inner_join(d_course, by = "Course ID") %>%
  group_by(Cluster) %>%
  summarise(n = n(),
            Min = min(Grade), 
            Max = max(Grade), 
            Mean = round(mean(Grade), 2), 
            Median = median(Grade), 
            SD = sd(Grade), 
            `Proportion Failed` = mean(Grade < 5.5))

year_statistics <- exploration %>%
  inner_join(d_course, by = "Course ID") %>%
  group_by(Year_numerical) %>%
  summarise(n = n(),
            Min = min(Grade), 
            Max = max(Grade), 
            Mean = round(mean(Grade), 2), 
            Median = median(Grade), 
            SD = sd(Grade), 
            `Proportion Failed` = mean(Grade < 5.5))

level_statistics <- exploration %>%
  inner_join(d_course, by = "Course ID") %>%
  group_by(Level) %>%
  summarise(n = n(),
            Min = min(Grade), 
            Max = max(Grade), 
            Mean = round(mean(Grade), 2), 
            Median = median(Grade), 
            SD = sd(Grade), 
            `Proportion Failed` = mean(Grade < 5.5))

percentage_grades_awarded <- d_transcript %>%
          mutate(Grade = str_replace(string = Grade, pattern = ",",replace = "."),
                 Grade = as.integer(Grade)) %>%
  filter(Year_numerical %in% c(2015,2016))%>%
  mutate(total=n())%>%
  group_by(Grade) %>%
  mutate(grade_total=n())%>%
  select(Grade, grade_total,total)%>%
  distinct()%>%
  mutate(Percentage = signif(grade_total/total,digits=2))%>%
  arrange(Grade)

```
We have found some NA values for the grades! Students:

0177849 - COR1003 & EMTH0001  +++++++++++++++ Master thesis should not be showing up! +++++++++++++
0177857
0222100
0270148
0313173
0317101
0317349

```{r}
#We have NA in grades. Something weird is happening. 
summary(str_detect(d_transcript$Grade, pattern="NA")) #shows NA's = 312 FALSE= 89069 WHY ARE THERE NAs?

has_na <- d_transcript %>%
  mutate(What = str_detect(Grade, pattern="NA")) %>%
  filter(is.na(What))
```

##Getting dates
For a first exploration of arules, we conceptualise our framework like this:
transaction = student
item = course

###Data preparation
First we transform our data into transaction data. For this, we first create a vector of mandatory courses that we exclude from transcripts. 

```{r}
d_transactions <- d_course %>%
  select(Type, Code, Letters) %>%
  filter(Type == "Elective",
         ! Letters %in% c("SKI", "PRO"),
         ! Letters %in% c("SAS", "SAH", "SAC")) %>%
  select(Code) %>%
  left_join(d_transcript, by = c("Code" = "Course Code")) %>%
  select(`Student ID Number`, Code) %>%
  group_by(`Student ID Number`) %>%
  summarize(list_course = list(Code)) %>%
  group_by()

transactions <- as(d_transactions$list_course, "transactions")
```

We apply Apriori algorithm:
```{r}
results <- apriori(
  data = transactions, 
  parameter = list(
    supp = 0.02,
    smax = 1, # max support
    conf = 0.4,
    minlen = 2,
    maxlen = 2
    ),
  appearance = NULL,
  control = NULL
  ) %>%
  inspect

colnames(results)[2] <- "association"

results %>%
  arrange(desc(confidence))
```
Now we include data for pass and fail:
```{r}
d_transaction_passed <- d_course %>%
  select(Type, Code, Letters) %>%
  filter(Type == "Elective",
         ! Letters %in% c("SKI", "PRO"),
         ! Letters %in% c("SAS", "SAH", "SAC")) %>%
  select(Code) %>%
  left_join(d_transcript, by = c("Code" = "Course Code")) %>%
  mutate(Outcome = case_when(Grade=="NG"~"Fail",
                             Grade > 5.5 ~"Pass",
                             T~"Fail")) %>%
  mutate(Item= paste(Code, Outcome, sep = "_")) %>%
  select(`Student ID Number`, Item) %>%
  group_by(`Student ID Number`) %>%
  summarize(list_course = list(Item)) %>%
  group_by()

transactions_passed <- as(d_transaction_passed$list_course, "transactions")

```
We apply Apriori algorithm:
```{r}
results_passed <- apriori(
  data = transactions_passed, 
  parameter = list(
    supp = 0,
    smax = 1, # max support
    conf = 0.4,
    minlen = 2,
    maxlen = 2
    ),
  appearance = NULL,
  control = NULL
  ) %>%
  inspect

colnames(results_passed)[2] <- "association"

results_passed %>%
  separate(lhs, into = c("LHS", "LHS_pass"), sep= "_", remove = F) %>%
  separate(rhs, into = c("RHS", "RHS_pass"), sep= "_", remove = F) %>%
  filter(RHS_pass == "Fail}") %>%
  arrange(desc(count))
```

#Mining-sequences:
The parameter values are: 
support:  a numeric value specifying the minimum support of a sequence (default 0.1, range [0,1]).
maxsize:  an integer value specifying the maximum number of items of an element of a sequence (default 10, range > 0).
maxlen:   an integer value specifying the maximum number of elements of a sequence (default 10, range > 0).
mingap:   an integer value specifying the minimum time difference between consecutive elements of a sequence (default none, range >= 1).
maxgap:   an integer value specifying the maximum time difference between consecutive elements of a sequence (default none, range >= 0).
maxwin:   an integer value specifying the maximum time difference between any two elements of a sequence (default none, range >= 0).

##Preparing data frame:
```{r}
fail_threshold <- 6.5

category <-quo(Low_grade) #Outcome or Low_grade or Discrete_grade or #None


d_sequence_transactions <- d_course %>%
  
  select(Type, `Course ID`, Letters) %>%
  
  filter(Type == "Elective",
         ! Letters %in% c("SKI", "PRO"),
         ! Letters %in% c("SAS", "SAH", "SAC")) %>%
  
  select(`Course ID`) %>%
  
  left_join(d_transcript, by = "Course ID") %>%
  # filter(!is.na(Grade)) %>% #remove NaN
  # filter(Grade != -1) %>% #remove NG
  mutate(
    Outcome = 
           case_when( Grade == -1   ~"Fail", #if we don't do this NG satisfies the condition for pass v
                      Grade  > 5.5 ~"Pass",
                               T~"Fail"),
    Low_grade =
           case_when(Grade == -1 ~"low score", #if we don't do this NG satisfies the condition for pass v
                      Grade > fail_threshold ~"high score",
                               T~"low score"),
    Discrete_grade =
           case_when(Grade <= 5.4             ~ 5.0,
                     between(Grade, 5.5, 6.4) ~ 6.0,
                     between(Grade, 6.5, 7.4) ~ 7.0,
                     between(Grade, 7.5, 8.4) ~ 8.0,
                     between(Grade, 8.5, 9.4) ~ 9.0,
                     Grade >= 9.5             ~ 10.0,
                     T ~ -99999    #this is a control, we should not have any grades here
                     ),
    None= "" # this might not be optimal
         ) %>%
  
  mutate(Item = paste(`Course ID`, !!category, sep = "_")) %>% #Change for Outcome/Low_grade/Discrete_grade
  
  filter(!str_detect(Period, " to ")) %>% #filter courses that spann more than one period
  
  mutate( Time = paste(Year_numerical, Period, sep = ""),
          Time = as.double(Time)) %>%
  
  select(`Student ID`, Item, Time) %>%
  
  arrange(`Student ID`, Time) %>% #Note that integer identifiers must be positive and that transactions must be ordered by sequenceID and eventID.
  
  group_by(`Student ID`, Time) %>%
  
  summarize(list_course = list(Item)) %>%
  
  mutate(TransactionID = paste(`Student ID`, Time, sep = "_"))

```

##to transaction
```{r}
transaction_list_course <- d_sequence_transactions$list_course
names(transaction_list_course) <- d_sequence_transactions$TransactionID

transactions <- as(transaction_list_course, "transactions")
transactionInfo(transactions)$sequenceID <- d_sequence_transactions$`Student ID`
transactionInfo(transactions)$eventID <- d_sequence_transactions$Time
transactionInfo(transactions)$transactionID <- NULL

#checking results
as(transactions, "data.frame")
```

##Rule induction
##Creating look-up table
```{r}
lookup_table <- d_course %>%
  
  select(Type, `Course ID`, Letters) %>%
  
  filter(Type == "Elective",
         ! Letters %in% c("SKI", "PRO"),
         ! Letters %in% c("SAS", "SAH", "SAC")) %>%
  
  select(`Course ID`) %>%
  
  left_join(d_transcript, by = "Course ID") %>%
  mutate(
    Outcome = 
           case_when( Grade == -1   ~"Fail", #if we don't do this NG satisfies the condition for pass v
                      Grade  > 5.5 ~"Pass",
                               T~"Fail"),
    Low_grade =
           case_when(Grade == -1 ~"low score", #if we don't do this NG satisfies the condition for pass v
                      Grade > fail_threshold ~"high score",
                               T~"low score"),
    Discrete_grade =
           case_when(Grade <= 5.4             ~ 5.0,
                     between(Grade, 5.5, 6.4) ~ 6.0,
                     between(Grade, 6.5, 7.4) ~ 7.0,
                     between(Grade, 7.5, 8.4) ~ 8.0,
                     between(Grade, 8.5, 9.4) ~ 9.0,
                     Grade >= 9.5             ~ 10.0,
                     T ~ -99999    #this is a control, we should not have any grades here
                     ),
    None= "" # this might not be optimal
         ) %>%
  
  #mutate(Item = paste(`Course ID`, !!category, sep = "_")) %>% #Change for Outcome/Low_grade/Discrete_grade
  
  filter(!str_detect(Period, " to ")) %>% #filter courses that spann more than one period
  
  mutate( Time = paste(Year_numerical, Period, sep = ""),
          Time = as.double(Time)) %>%
  
  select(`Student ID`, #Item, 
         `Course ID`, !!category, Time) %>% # Course ID and Time may not be necessary
  
  arrange(`Student ID`, Time) %>% #Note that integer identifiers must be positive and that transactions must be ordered by sequenceID and eventID.
  
  group_by(`Course ID`, !!category) %>% ##this makes no sense we should just group id and low_grade
  
  summarize(Count = n()) %>%
  #separate(Item, into= c("Course ID", quo_name(category)), sep="_", remove = F) %>%
  ungroup() %>%
  group_by(`Course ID`) %>%
  mutate(Total= sum(Count))%>%
  filter(Low_grade=="low score")%>%
  mutate(Prop_low= Count/Total)
```

###NOTE for FURTURE: create filter by function
##Create filter condition.
```{r}
string_filter <- case_when(quo_name(category)=="Outcome"        ~ "Fail",
                           quo_name(category)=="Low_grade"      ~ "low score",
                           quo_name(category)=="Discrete_grade" ~ "5",
                           quo_name(category)=="None"           ~ "_" #useless filter
                           )
```
##CSPADE Algorithm:
```{r}
frequent_trajectories <- cspade(transactions, parameter = list(support = 0,
                                                               maxsize = 1,
                                                               maxlen = 2), control   = list(verbose = TRUE))

#Inspect results CSPADE
summary(frequent_trajectories)
as(frequent_trajectories, "data.frame")

```
##rule induction:
```{r}
rules <- ruleInduction(frequent_trajectories,
                       confidence = 0, #we need to play with the parameters.
                       control    = list(verbose = TRUE))


pass_rules_df <- as(rules, "data.frame") %>%
  
  separate(rule, into=c("LHS", "RHS"), sep = "=>", remove = T) %>% #remove = F to keep columns
  
#  filter(str_detect(RHS, string_filter)) %>% #FILTER (YES) --> uncomment, (NO)-->comment
  
  arrange(
    LHS, RHS,
    desc(confidence), desc(lift))

```
##calculate appropriate measures:
```{r}
n_students <- length(unique(d_sequence_transactions$`Student ID`))

sequence_rules <- pass_rules_df %>%
  separate(LHS, into=c("LHS Course ID", "LHS Score"), sep="_", remove= FALSE) %>%
  separate(RHS, into=c("RHS Course ID", "RHS Score"), sep="_", remove= FALSE) %>%
  mutate(`RHS Course ID`= substr(`RHS Course ID`, start=4, stop=10))%>%
  left_join(lookup_table, by = c("RHS Course ID"="Course ID")) %>%
  
  # Compute statistics
  group_by(LHS,`RHS Course ID`) %>%
  mutate(Prob_both = sum(support), 
         Conf_corr = support/Prob_both,
         n_rule = support * n_students,
         n_both =Prob_both * n_students,
         lift_diff= Conf_corr - Prop_low,
         lift_corr=Conf_corr / Prop_low) %>%
  ungroup() %>%
  
  # Filter and edit output
  filter(str_detect(`RHS Score`, pattern = "low"),
         str_detect(`LHS Score`, pattern = "low"),
         n_rule >= 5,
         Conf_corr > 0.2) %>%
  select(LHS, RHS, support, n_rule, Prob_both, n_both, Prop_low, Conf_corr, lift_corr, lift_diff) %>%
  mutate(support = round(support,3),
         Prob_both =round(Prob_both,3),
         Prop_low =round(Prop_low,3),
         Conf_corr= round(Conf_corr,3),
         lift_diff= round(lift_diff,3),
         lift_corr= round(lift_corr,3)) %>%
  arrange(lift_diff)

```
##Save data
```{r}
save(sequence_rules,
     file = "sequence_rules.RDATA")
```

##Arrange data for plots:
```{r}
for_plots <-  manual_confidence_rules %>%
  group_by(LHS)%>%
  mutate(LHS_count=n())
```
#Visualizing rules
```{r}
#look at counts
ggplot(for_plots, aes(LHS))+
  geom_bar()

#jitter
ggplot(manual_confidence_rules)+
  geom_jitter(mapping=aes(x=Conf_corr, y=log(support), color=lift_corr))

ggplot(manual_confidence_rules)+
  geom_jitter(mapping=aes(x=log(support), y=lift_corr, color = Conf_corr))

#heatmap
ggplot(select(manual_confidence_rules,LHS,RHS, n_rule), aes(x=RHS,y=LHS, fill=n_rule))+
  geom_raster() +
  theme(
    axis.text.x = element_text(angle=90)
  )

gglot(table(select(manual_confidence_rules,LHS,RHS)))

#ggnetwork

#SEE: http://kateto.net/network-visualization 
g_net <- graph_from_data_frame(d=head(for_plots,50), directed=T) #I BELIEVE THE COLUMNS SHOULD BE REVERSED.

l <- layout_in_circle(g_net)
plot(g_net, #vertex.shape="none",
     vertex.size=.9,
     #vertex.label=NA,
     vertex.label.cex=0.5,
     edge.arrow.size=.1, 
     edge.curved=.1,
     layout=l)

```
#Visualisation
It might be a nice idea to visualise using Sankey diagrams, although I don't know if there will be too many courses for it to be meaningful. We might need to sample. See https://analyzecore.com/2014/10/31/sequence-carts-analysis-sankey/ 

#EXPERIMENTS:
##Condensing grades

```{r}

probabilities_manipulated <- d_transcript %>%
  transmute(tmp_id=paste(`Student ID`,`Course ID`,Year_numerical,Period,`Number Repeated Attempt`,sep="_"),
            Round_grade= round(Grade,0))
student_set <- unique(probabilities_manipulated$tmp_id)

for student %in% student_set

```

##Puting students into take and not take. 
```{r}
#This df has 731,676 rows:
test <- expand.grid(`Student ID`= unique(d_transcript$`Student ID`),`Course ID`= unique(d_course$`Course ID`)) %>%
  left_join(d_transcript, by=c("Course ID", "Student ID")) %>%
  select(`Course ID`, `Student ID`, Grade, Year_numerical, Period) %>%
  mutate(
    take_course = case_when(
      is.na(Grade)  ~ FALSE,
      T             ~ TRUE
      ),
    PFN = case_when(
      is.na(Grade)  ~ "not",
      Grade >= 5.5  ~ "pass",
      Grade < 5.5   ~ "fail"
      )
    )

table(test$PFN)

```